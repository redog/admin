# NotionChat

## Overview

This project attempts to automate the process of connecting Notion databases to the `sigoden/aichat` command-line tool via the `sigoden/llm-functions` project.  

The core idea is to:
1.  Introspect the schema of a Notion database.
2.  Dynamically generate a Flask API server providing CRUD (Create, Read, Update, Delete) access to that specific database.
3.  Dynamically generate a Python "Common Tool" script compatible with `sigoden/llm-functions`, which interacts with the Flask API.
4.  Integrate this tool script into the `llm-functions` build process.
5.  Allow interaction with the Notion database via natural language using `aichat` and the built-in `%functions%` role.

**Current Status:** This setup uses the "Common Tool" approach (one tool file per database, used via the `%functions%` role) as a workaround while waiting for enhanced multi-agent role support in `aichat`. The Flask API currently serves only one database at a time. I have included a -p option for running multiple instances for now.

## Prerequisites

* **Python:** Version 3.10 or higher recommended.
    pip install flask notion-client requests re
* **jq**  
* **Git:** Required for cloning repositories.
* **Notion:**
    * A Notion account.
    * A Notion Integration Token created via [My Integrations](https://www.notion.so/my-integrations). Ensure the integration has appropriate permissions for the databases you want to access.
* **AIChat:** Installed. See <https://github.com/sigoden/aichat>.
* **Argc:** Installed (dependency for `llm-functions`). See <https://github.com/sigoden/argc>.
* **llm-functions Repository:** Cloned locally. See <https://github.com/sigoden/llm-functions>.

## Scripts Overview

Place these scripts in your project's working directory (e.g., `notionchat/`).

1.  **`flask_api_generator.py`**:
    * Connects to Notion.
    * Prompts the user to select a database.
    * Starts a Flask development web server (default: port 5002) that provides a REST API for CRUD operations on the **single selected database**. This needs to be kept running in a separate terminal during `aichat` usage.
2.  **`llm_client_generator.py`**:
    * Connects to Notion.
    * Prompts the user to select a database.
    * Generates the Python code for a "Common Tool" script compatible with `sigoden/llm-functions`. This script contains a single `run` function that handles `list`, `get`, `create`, `update`, and `delete` actions by calling the Flask API generated by `flask_api_generator.py`.
    * Outputs the generated Python code to standard output.
3.  **`integrate_llm_functions.py`**:
    * Takes the path to your `llm-functions` clone and the path to the directory containing the generated tool script(s) as arguments.
    * Copies the generated tool script (e.g., `camera_inventory_tool.py`) into the `tools/` subdirectory of the `llm-functions` repository.
    * Appends the tool's filename to the `tools.txt` file in the `llm-functions` repository root (if not already present).
    * Runs `argc build` within the `llm-functions` repository to update `functions.json`.
    * Optionally runs `argc link-to-aichat`.

## Setup

1.  **Clone `llm-functions`:**
    ```bash
    git clone [https://github.com/sigoden/llm-functions](https://github.com/sigoden/llm-functions) path/to/your/llm-functions
    ```
2.  **Install Python Dependencies:**
    ```bash
    pip install notion-client flask requests re
    # Or use your venv: python -m pip install ...
    # remember to activate the venv in both the aichat terminal and the flask server's terminal.
    ```
3.  **Set Environment Variable:** Set the `NOTION_API_TOKEN` environment variable with your Notion integration token.
    ```bash
    # Example (macOS/Linux) - Add to .zshrc, .bashrc, or .profile
    export NOTION_API_TOKEN="secret_YOUR_NOTION_TOKEN"

    # Example (Windows - PowerShell)
    $env:NOTION_API_TOKEN="secret_YOUR_NOTION_TOKEN"
    # (Consider adding it permanently via System Properties)
    ```
    *Restart your terminal after setting the variable.*
4.  **Place Scripts:** Copy `flask_api_generator.py`, `llm_client_generator.py`, and `integrate_llm_functions.py` into your project directory.
5.  **Create Output Directory:** Create a directory to hold the generated client tool files:
    ```bash
    mkdir generated_clients
    ```
6.  **Verify Tools:** Ensure `aichat` and `argc` are installed correctly and accessible in your PATH.

## Workflow: Integrating a Database Tool

Repeat these steps for each Notion database you want to integrate.

1.  **Generate Tool Script:**
    * Run the client generator, select the desired database (e.g., "Camera Inventory"), and redirect the output to save the tool file. Use a `_tool.py` suffix.
        ```bash
        # Activate your Python venv first if needed
        python llm_client_generator.py > generated_clients/camera_inventory_tool.py
        ```
2.  **Integrate with `llm-functions`:**
    * Run the integration script, providing the paths. Ensure `llm-functions/tools.txt` is empty or contains only other valid common tools you want to keep.
        ```bash
        python integrate_llm_functions.py path/to/your/llm-functions ./generated_clients
        ```
    * **Check Output:** Verify that the script copies the file to `llm-functions/tools/`, appends the filename to `tools.txt`, and that the `argc build` command completes successfully without errors (especially Python tracebacks in stderr).
3.  **Run Flask API Backend:**
    * In a **separate terminal**, start the Flask API server, selecting the **same database** you chose in Step 1 (e.g., "Camera Inventory").
        ```bash
        # Activate your Python venv first if needed
        python flask_api_generator.py
        # (Select "Camera Inventory" when prompted)
        ```
    * Keep this terminal running.
4.  **Test with `aichat`:**
    * In **another terminal** (ensure your venv is active if `aichat` relies on it), use the built-in `%functions%` role. You need to tell the LLM which tool to run (using the filename without `.py`) and provide the `action` and necessary parameters.
        ```bash
        # Example: List all cameras
        aichat --role %functions% "run camera_inventory_tool action=list"

        # Example: List specific cameras
        aichat --role %functions% "use camera_inventory_tool action=list manufacturer=Flir"

        # Example: Create a camera
        aichat --role %functions% "run camera_inventory_tool action=create name='Office Cam 1' ip_address='192.168.1.100' manufacturer='Avigilon'"

        # Example: Update a camera
        aichat --role %functions% "run camera_inventory_tool action=update 'Office Cam 1' network_status=Online"

    * Check the `aichat` response and the Flask API server terminal for logs/hits.

## Current Limitations

* **Single DB Flask API:** The `flask_api_generator.py` script currently only serves one database per running instance. To interact with different databases via `aichat`, you need to stop and restart the Flask API, selecting the appropriate database each time.
* **Complex `run` Function:** The generated common tool uses a single `run` function with many optional parameters. You may need to be quite specific in your `aichat` prompts to ensure the LLM extracts the correct `action` and parameters.
* **`argc build` Sensitivity:** The `argc build` process has shown sensitivity to Python type hints and environment issues. Ensure it completes successfully during integration.
* **No Multi-Agent Role:** This setup uses the `%functions%` role. A dedicated role combining multiple database agents (`use_tools: agent1,agent2,...`) depends on future `aichat` updates.

## Future Work

* Refactor `flask_api_generator.py` to optionally load multiple schemas and serve APIs for all integrated databases simultaneously using Flask Blueprints.
* Once `aichat` supports multi-agent roles reliably via `use_tools`, switch back to the agent-based structure using the generator from `llm_client_generator.py` (Agent Tool Format) and the integrator from `integrate_llm_functions.py` (Single Combined Role).

## Much AI was employed in the construction of this code. Mostly in fact. Use at your own risk and data peril.   
